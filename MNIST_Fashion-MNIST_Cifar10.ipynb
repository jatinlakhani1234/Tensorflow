{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices()\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simple_Dense_Model(train_data, train_label, test_data, test_label, lr, input_shape=(28*28), output_shape=10):\n",
    "    \n",
    "    # Flattening and normalizing images\n",
    "    X_train = train_data.reshape(-1, input_shape).astype('float32') / 255.0\n",
    "    X_test = test_data.reshape(-1, input_shape).astype('float32') / 255.0\n",
    "    \n",
    "    # Model\n",
    "    model = keras.Sequential([keras.Input(shape=input_shape), #(28*28)\n",
    "                         keras.layers.Dense(512, activation='relu'),\n",
    "                         keras.layers.Dense(256, activation='relu'),\n",
    "                         keras.layers.Dense(output_shape, activation='softmax')])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    #Fit\n",
    "    model.fit(X_train, train_label, batch_size=32, epochs=5)\n",
    "    \n",
    "    #Evaluate\n",
    "    model.evaluate(X_test, test_label, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X_train, y_train, X_test, y_test, lr, input_shape=(28,28,1), output_shape=10):\n",
    "    \n",
    "    # Flattening and normalizing images\n",
    "    \"\"\"Now for Convolution layers we have to reshape our input into a single tenor. That's because the first convolution\n",
    "    expects a single tensor containing everything, so instead of 60,000 items (size = 28x28x1) in a list, we have a single\n",
    "    4D list that is 60,000x28x28x1.\"\"\"\n",
    "    X_train = X_train.reshape(-1, input_shape[0], input_shape[1], input_shape[2]).astype('float32') / 255.0\n",
    "    X_test = X_test.reshape(-1, input_shape[0], input_shape[1], input_shape[2]).astype('float32') / 255.0\n",
    "    \n",
    "    # Model\n",
    "    model = keras.Sequential([keras.Input(shape=input_shape), #(32,32,3)\n",
    "                              keras.layers.Conv2D(32, (3,3), padding='valid', activation='relu'),\n",
    "                              keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                              keras.layers.Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "                              keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                              keras.layers.Conv2D(128, (3,3), padding='valid', activation='relu'),\n",
    "                              keras.layers.Flatten(),\n",
    "                              keras.layers.Dense(64, activation='relu'),\n",
    "                              keras.layers.Dense(output_shape, activation='softmax')])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    #Fit\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5)\n",
    "    \n",
    "    #Evaluate\n",
    "    model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X_train, y_train, X_test, y_test, lr, input_shape=(28,28), output_shape=10):\n",
    "    \n",
    "    # Flattening and normalizing images\n",
    "    X_train = X_train.reshape(-1, input_shape[0], input_shape[1]).astype('float32') / 255.0\n",
    "    X_test = X_test.reshape(-1, input_shape[0], input_shape[1]).astype('float32') / 255.0\n",
    "    \n",
    "    # Model\n",
    "    model = keras.Sequential([keras.Input(shape=(None, input_shape[1])), #(None,28)\n",
    "                             keras.layers.SimpleRNN(256, return_sequences=True, activation='relu'),\n",
    "                             keras.layers.SimpleRNN(256, activation='relu'),\n",
    "                             keras.layers.Dense(output_shape, activation='softmax')])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    #Fit\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5)\n",
    "    \n",
    "    #Evaluate\n",
    "    model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mnist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=50\n",
    "plt.title(\"The label of image is \"+str(y_train_mnist[x]))\n",
    "plt.imshow(X_train_mnist[x], cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1854 - accuracy: 0.9437\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0784 - accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0421 - accuracy: 0.9869\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0328 - accuracy: 0.9888\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0795 - accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "Simple_Dense_Model(X_train_mnist, y_train_mnist, X_test_mnist, y_test_mnist, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **98.88%** and test set accuracy is **97.89%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 167,114\n",
      "Trainable params: 167,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1348 - accuracy: 0.9573\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0445 - accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0231 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "CNN(X_train_mnist, y_train_mnist, X_test_mnist, y_test_mnist, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **99.4%** and test set accuracy is **99.17%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "Images(28*28) will go in row by row(\"28 rows, each row at a time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, None, 256)         72960     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 206,858\n",
      "Trainable params: 206,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.3012 - accuracy: 0.9077\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.1486 - accuracy: 0.9594\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1234 - accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1151 - accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0957 - accuracy: 0.9735\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0854 - accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "RNN(X_train_mnist, y_train_mnist, X_test_mnist, y_test_mnist, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **97.35%** and test set accuracy is **97.51%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try on MNIST Fashion dataset\n",
    "Dataset of images of 10 different classes\n",
    "- 60000 training images\n",
    "- 10000 test images\n",
    "- 28*28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXGElEQVR4nO3de5BcZZnH8e+PcAm5kAshkAQkoFFRS8MakAJkAQWRWgVvUWp1sbzEZbVca3HVxQsssiuF961F13hF8LIqUMKKIrK6aAUlI4tJIKsmAcyQMAmQO4Hcnv2jT3SIc9530t3T3fD+PlVT091Pv33ePj3PnNPnOe95FRGY2VPfPt3ugJl1hpPdrBBOdrNCONnNCuFkNyuEk92sEE72vSDpEknXtOm1vibpsmE+92eS3tbkclppe4GkAUmbJR28R+xp1eOjmnntTpH0H5I+3O1+9IJ9u92BXiJp86C7Y4DHgZ3V/Xd0vkfdI2k/4FPACRHxmz3jEfEHYFzHO7aXIuJvm2kn6UTgM8AxwL3A30XEL9rYtY7zln2QiBi3+wf4A/CKQY99o9v967BDgdHA3d3uSKdJmgzcAHwcmAhcAdwoaVI3+9UqJ/ve21/S1yVtknS3pDm7A5KmS7pW0lpJ90p693BeUNIkSf9VtVtX3T58j6c9XdIdkjZI+n71B7m7/QmSFkhaL+k3kk4d5nIPkPQZSauqn89Ujz0T+G31tPWS/nuItjMlhaR9q/s/k3RZ1Y/Nkm6UdLCkb0jaKGmhpJmD2n9W0soq9mtJLx4UO1DSVdW6WCrpfZL6B8WHvZ4Hf12SNKVat+slPSLp55KGyoETgYGI+G5E7IyIa4C1wKuHs157lZN9770S+DaN//g3AP8OUP3R3Aj8BpgBvAR4j6SXDeM19wG+ChwJPA3Yuvt1B/kb4C3AdGAH8G/VcmcAPwAuAyYD7wWulXTIMJb7QeAEYDbwAuB44EMR8TvgudVzJkbE6cN4LYA3AG+i8f6fDtxeva/JwFLg4kHPXVgtdzLwTeC7kkZXsYuBmcDRwBnAG3c3anE9Xwj0A4fQ2HO5CBjqfHFVP3s+9rxhLKNnOdn33i8i4qaI2AlcTSNJAI4DDomISyNiW0SsAL5IIwGSIuLhiLg2Ih6NiE3AvwB/ucfTro6IJRGxBfgwMLc6OPZG4KaqT7si4hagDzh7GO/lr4FLI2JNRKwF/plGsjbrqxGxPCI2AD8ElkfETyJiB/Bd4NhB7/ma6n3viIhPAgcAz6rCc4F/jYh1EdFP9Y+t0vR6BrYD04AjI2J7RPw8hh4csgCYLuk8SftJOp/GP68xe7Myeo2Tfe89OOj2o8Doalf2SBp/IOt3/9DYchyae0FJYyR9QdL9kjYCtwET9zjSvXLQ7fuB/YAp1XJft8dyT6bxR50zvXqtwa87fRjt6gwMur11iPt/PKAn6cJqF31D1ecJNN7P7n4Nfr+Dbze9nml8B18G/FjSCkkfGOpJEfEwcA7wD9V7OAv4CY29gictH41vn5XAvRExq4m2F9LYqr0oIh6UNBv4X564K3nEoNtPo7GVeqha7tUR8fYmlruKRvLsPgj3tOqxEVV9P38/jV3wuyNil6R1/On9rgYOB+6p7g9+702v52qv6ULgQknPBX4qaWFE3DrEc/+Hxl4E1T/z5cAn93aZvcRb9va5A9go6f3VAaZRkp4n6bhhtB1PY8u3vjrwdvEQz3mjpOdIGgNcCnyv+ipxDfAKSS+rljla0qlDHOAbyreAD0k6RNIU4CPV64208TSOO6wF9pX0EeCgQfHvAP9UHbicAbxrUKzp9SzpryQ9Q5KAjTTKqjtrnntstQt/EPAJoD8ibm7mzfYKJ3ubVIn3ChoHne6lsdX9Eo3d05zPAAdWbX4J/GiI51wNfI3G14jRwLur5a6ksct5EY3kWQn8I8P7bC+j8f1+EbAYuLN6bKTdTOM7/e9ofHV4jCfuql9KY5f5Xhq7z9+jcc5Dq+t5VvV6m2kcPPxcRPys5rnv4097TtOAVw3zvfUs+eIV1uskXQC8ISL2PGhpe8Fbdus5kqZJOknSPpKeReN79vXd7teTnQ/QWS/aH/gCcBSwnsZ5DZ/rZoeeCrwbb1YI78abFaKju/GSvBthNsIiYs9TfYEWt+ySzpL0W0nL6s5GMrPe0PR39upUzt/RGKjQT2Ngw3kRcU+ijbfsZiNsJLbsxwPLImJFRGyjccT0nBZez8xGUCvJPoMnnvXUXz32BJLmSeqT1NfCssysRa0coBtqV+HPdtMjYj4wH7wbb9ZNrWzZ+3niaKTD6cCIKTNrTivJvhCYJekoSfvTuHjADe3plpm1W9O78RGxQ9K7aIxgGgV8JSKKuzih2ZNFR0+X9Xd2s5E3IifVmNmTh5PdrBBOdrNCONnNCuFkNyuEk92sEE52s0I42c0K4WQ3K4ST3awQTnazQjjZzQrhZDcrhGeEeYprTFhar9VRj+PHj0/GTz755NrYD3/4w5aWnXtvo0aNqo3t2LGjpWW3Ktf3lGY/M2/ZzQrhZDcrhJPdrBBOdrNCONnNCuFkNyuEk92sEK6zP8Xts0/6//nOnTuT8Wc84xnJ+Nve9rZkfOvWrbWxLVu2JNs+9thjyfgdd9yRjLdSS8/VwXPrNde+lb6lzh9IfZ7espsVwsluVggnu1khnOxmhXCymxXCyW5WCCe7WSFcZ3+KS9VkIV9nP/3005Pxl770pcl4f39/beyAAw5Ith0zZkwyfsYZZyTjX/rSl2pjAwMDyba5MeO59ZYzbty42tiuXbuSbR999NGmltlSsku6D9gE7AR2RMScVl7PzEZOO7bsp0XEQ214HTMbQf7OblaIVpM9gB9L+rWkeUM9QdI8SX2S+lpclpm1oNXd+JMiYpWkqcAtkv4vIm4b/ISImA/MB5DU2tUNzaxpLW3ZI2JV9XsNcD1wfDs6ZWbt13SySxorafzu28CZwJJ2dczM2quV3fhDgeurcbv7At+MiB+1pVfWNtu2bWup/XHHHZeMz5w5MxlP1flzY8JvvvnmZPzYY49Nxq+44oraWF9f+hDS4sWLk/GlS5cm48cfn97JTa3XBQsWJNvefvvttbHNmzfXxppO9ohYAbyg2fZm1lkuvZkVwsluVggnu1khnOxmhXCymxVCrU7Zu1cL8xl0IyJ12eLc55sbJpoqXwFMnDgxGd++fXttLDeUM2fhwoXJ+LJly2pjrZYkp02bloyn3jek+/7a17422fbKK6+sjfX19bFx48Yh/yC8ZTcrhJPdrBBOdrNCONnNCuFkNyuEk92sEE52s0K4zt4DctP7tiL3+f7yl79MxnNDWHNS7y03bXGrtfDUlM+5Gv+dd96ZjKdq+JB/b2eddVZt7Oijj062nTFjRjIeEa6zm5XMyW5WCCe7WSGc7GaFcLKbFcLJblYIJ7tZITxlcw/o5LkOe1q3bl0ynhu3vXXr1mQ8NS3zvvum//xS0xpDuo4OcOCBB9bGcnX2F7/4xcn4iSeemIznLpM9derU2tiPfjQyV2T3lt2sEE52s0I42c0K4WQ3K4ST3awQTnazQjjZzQrhOnvhxowZk4zn6sW5+KOPPlob27BhQ7Ltww8/nIznxtqnzl/IXUMg975y623nzp3JeKrOf8QRRyTbNiu7ZZf0FUlrJC0Z9NhkSbdI+n31e9KI9M7M2mY4u/FfA/a8rMYHgFsjYhZwa3XfzHpYNtkj4jbgkT0ePge4qrp9FXBue7tlZu3W7Hf2QyNiNUBErJZUe6KvpHnAvCaXY2ZtMuIH6CJiPjAffMFJs25qtvQ2IGkaQPV7Tfu6ZGYjodlkvwE4v7p9PvD99nTHzEZKdjde0reAU4EpkvqBi4HLge9IeivwB+B1I9nJp7pWa76pmm5uTPj06dOT8ccff7yleGo8e+668KkaPeTnhk/V6XN18v333z8Z37RpUzI+YcKEZHzRokW1sdxnNmfOnNrYPffcUxvLJntEnFcTekmurZn1Dp8ua1YIJ7tZIZzsZoVwspsVwsluVggPce0BuUtJjxo1KhlPld5e//rXJ9sedthhyfjatWuT8dTlmiE9lHPs2LHJtrmhnrnSXarst3379mTb3GWuc+/74IMPTsavvPLK2tjs2bOTbVN9S5VxvWU3K4ST3awQTnazQjjZzQrhZDcrhJPdrBBOdrNCqJPTBftKNUPL1XR37NjR9Gu/6EUvSsZ/8IMfJOO5KZlbOQdg/Pjxyba5KZlzl5reb7/9mopB/hyA3FTXOan39vGPfzzZ9pprrknGI2LIYru37GaFcLKbFcLJblYIJ7tZIZzsZoVwspsVwsluVogn1Xj21FjdXL03dznm3OWcU+OfU2O2h6OVOnrOTTfdlIxv2bIlGc/V2XOXXE6dx5EbK5/7TEePHp2M58ast9I295nn+v785z+/NpabyrpZ3rKbFcLJblYIJ7tZIZzsZoVwspsVwsluVggnu1kheqrO3srY6JGsVY+0U045JRl/zWtek4yfdNJJtbHctMe5MeG5OnpuLH7qM8v1Lff3kLouPKTr8LnrOOT6lpNbb5s3b66NvfrVr062vfHGG5vqU3bLLukrktZIWjLosUskPSDprurn7KaWbmYdM5zd+K8BZw3x+KcjYnb1kz5Ny8y6LpvsEXEb8EgH+mJmI6iVA3TvkrSo2s2fVPckSfMk9Unqa2FZZtaiZpP988DTgdnAauCTdU+MiPkRMSci5jS5LDNrg6aSPSIGImJnROwCvggc395umVm7NZXskqYNuvsqYEndc82sN2SvGy/pW8CpwBRgALi4uj8bCOA+4B0RsTq7sC5eN37y5MnJ+PTp05PxWbNmNd02Vzd95jOfmYw//vjjyXhqrH5uXHZunvFVq1Yl47nrr6fqzbk5zHPzr48ZMyYZX7BgQW1s3Lhxyba5cx9y49lzY9JT621gYCDZ9phjjknG664bnz2pJiLOG+LhL+famVlv8emyZoVwspsVwsluVggnu1khnOxmheipKZtPOOGEZPuPfvSjtbFDDjkk2XbixInJeGooJqSHW65fvz7ZNjf8NldCypWgUpfBzl0KeunSpcn43Llzk/G+vvRZ0KlpmSdNqj3LGoCZM2cm4zkrVqyojeWmi960aVMynhsCmytppkp/Bx10ULJt7u/FUzabFc7JblYIJ7tZIZzsZoVwspsVwsluVggnu1khOl5nT9Wrb7/99mT7adOm1cZydfJcvJVLB+cueZyrdbdqwoQJtbEpU6Yk2775zW9Oxs8888xk/IILLkjGU0NkH3vssWTbe++9NxlP1dEhPSy51eG1uaG9uTp+qn1u+OyRRx6ZjLvOblY4J7tZIZzsZoVwspsVwsluVggnu1khnOxmhehonX3KlCnxyle+sjZ++eWXJ9svX768Npa7NHAunpv+NyVXc03VwQFWrlyZjOcu55way5+6zDTAYYcdloyfe+65yXhqWmRIj0nPfSYvfOELW4qn3nuujp5bb7kpmXNS1yDI/T2lrvvw4IMPsm3bNtfZzUrmZDcrhJPdrBBOdrNCONnNCuFkNyuEk92sENlZXCUdAXwdOAzYBcyPiM9Kmgz8JzCTxrTNcyNiXeq1duzYwZo1a2rjuXpzaoxwblrj3Gvnar6pumruOt+PPPJIMn7//fcn47m+pcbL58aM565pf/311yfjixcvTsZTdfbcNNq5Wnjuev2p6apz7zs3pjxXC8+1T9XZczX81BTfqXUynC37DuDCiDgGOAF4p6TnAB8Abo2IWcCt1X0z61HZZI+I1RFxZ3V7E7AUmAGcA1xVPe0q4NwR6qOZtcFefWeXNBM4FvgVcGhErIbGPwRgatt7Z2ZtM+xklzQOuBZ4T0Rs3It28yT1SerLfQczs5EzrGSXtB+NRP9GRFxXPTwgaVoVnwYMeeQtIuZHxJyImNPq4AEza1422dU4bPhlYGlEfGpQ6Abg/Or2+cD32989M2uXbOkNOAl4E7BY0l3VYxcBlwPfkfRW4A/A63IvtG3bNh544IHaeG64bX9/f21s7Nixyba5SyrnyjgPPfRQbWzt2rXJtvvum17NueG1uTJPaphp7pLGuaGcqfcNcMwxxyTjW7ZsqY3lyqHr1iUrudn1lup7qiwH+dJcrn1uyubU0OINGzYk286ePbs2tmTJktpYNtkj4hdAXVHwJbn2ZtYbfAadWSGc7GaFcLKbFcLJblYIJ7tZIZzsZoUYTp29bbZu3cpdd91VG7/uuutqYwBvectbamO5yy3npvfNDQVNDTPN1cFzNdfcmYW5KaFTw3tzU1Xnzm3ITWW9evXqpl8/17fc+QmtfGatDp9tZXgtpOv4Rx11VLLtwMBAU8v1lt2sEE52s0I42c0K4WQ3K4ST3awQTnazQjjZzQrR0SmbJbW0sJe//OW1sfe+973JtlOnpi+Rlxu3naqr5urFuTp5rs6eqzenXj91yWLI19lz5xDk4qn3lmub63tOqn2qVj0cuc8sdynp1Hj2RYsWJdvOnTs3GY8IT9lsVjInu1khnOxmhXCymxXCyW5WCCe7WSGc7GaF6HidPXWd8lxtshWnnXZaMv6xj30sGU/V6SdMmJBsm7s2e64On6uz5+r8KakptCFfh0/NAwDpz3Tz5s3Jtrn1kpPqe268eW4cf+4zveWWW5LxpUuX1sYWLFiQbJvjOrtZ4ZzsZoVwspsVwsluVggnu1khnOxmhXCymxUiW2eXdATwdeAwYBcwPyI+K+kS4O3A7snJL4qImzKv1bmifgc9+9nPTsZbnRv+8MMPT8bvu+++2liunrx8+fJk3J586ursw5kkYgdwYUTcKWk88GtJu88Y+HREfKJdnTSzkZNN9ohYDayubm+StBSYMdIdM7P22qvv7JJmAscCv6oeepekRZK+ImlSTZt5kvok9bXWVTNrxbCTXdI44FrgPRGxEfg88HRgNo0t/yeHahcR8yNiTkTMab27ZtasYSW7pP1oJPo3IuI6gIgYiIidEbEL+CJw/Mh108xalU12NS7R+WVgaUR8atDj0wY97VXAkvZ3z8zaZTilt5OBnwOLaZTeAC4CzqOxCx/AfcA7qoN5qdd6SpbezHpJXentSXXdeDPL83h2s8I52c0K4WQ3K4ST3awQTnazQjjZzQrhZDcrhJPdrBBOdrNCONnNCuFkNyuEk92sEE52s0I42c0KMZyry7bTQ8D9g+5PqR7rRb3at17tF7hvzWpn346sC3R0PPufLVzq69Vr0/Vq33q1X+C+NatTffNuvFkhnOxmheh2ss/v8vJTerVvvdovcN+a1ZG+dfU7u5l1Tre37GbWIU52s0J0JdklnSXpt5KWSfpAN/pQR9J9khZLuqvb89NVc+itkbRk0GOTJd0i6ffV7yHn2OtS3y6R9EC17u6SdHaX+naEpJ9KWirpbkl/Xz3e1XWX6FdH1lvHv7NLGgX8DjgD6AcWAudFxD0d7UgNSfcBcyKi6ydgSDoF2Ax8PSKeVz12BfBIRFxe/aOcFBHv75G+XQJs7vY03tVsRdMGTzMOnAu8mS6uu0S/5tKB9daNLfvxwLKIWBER24BvA+d0oR89LyJuAx7Z4+FzgKuq21fR+GPpuJq+9YSIWB0Rd1a3NwG7pxnv6rpL9KsjupHsM4CVg+7301vzvQfwY0m/ljSv250ZwqG7p9mqfk/tcn/2lJ3Gu5P2mGa8Z9ZdM9Oft6obyT7U1DS9VP87KSL+Ang58M5qd9WGZ1jTeHfKENOM94Rmpz9vVTeSvR84YtD9w4FVXejHkCJiVfV7DXA9vTcV9cDuGXSr32u63J8/6qVpvIeaZpweWHfdnP68G8m+EJgl6ShJ+wNvAG7oQj/+jKSx1YETJI0FzqT3pqK+ATi/un0+8P0u9uUJemUa77ppxunyuuv69OcR0fEf4GwaR+SXAx/sRh9q+nU08Jvq5+5u9w34Fo3duu009ojeChwM3Ar8vvo9uYf6djWNqb0X0UisaV3q28k0vhouAu6qfs7u9rpL9Ksj682ny5oVwmfQmRXCyW5WCCe7WSGc7GaFcLKbFcLJblYIJ7tZIf4fYngPuC2YscgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=0\n",
    "plt.title(\"The label of image is \"+str(y_train_fashion[x]))\n",
    "plt.imshow(X_train_fashion[x], cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 1s - loss: 2.3741 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4659 - accuracy: 0.8303\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3535 - accuracy: 0.8696\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3190 - accuracy: 0.8821\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2941 - accuracy: 0.8909\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2771 - accuracy: 0.8962\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8724\n"
     ]
    }
   ],
   "source": [
    "Simple_Dense_Model(X_train_fashion, y_train_fashion, X_test_fashion, y_test_fashion, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **89.62%** and test set accuracy is **87.24%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 167,114\n",
      "Trainable params: 167,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4822 - accuracy: 0.8238\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3163 - accuracy: 0.8855\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2684 - accuracy: 0.9015\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2359 - accuracy: 0.9134\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2106 - accuracy: 0.9222\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2694 - accuracy: 0.9082\n"
     ]
    }
   ],
   "source": [
    "CNN(X_train_fashion, y_train_fashion, X_test_fashion, y_test_fashion, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **92.22%** and test set accuracy is **90.82%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 256)         72960     \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 206,858\n",
      "Trainable params: 206,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.6536 - accuracy: 0.7633\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.4616 - accuracy: 0.8375\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.4141 - accuracy: 0.8496\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.3947 - accuracy: 0.8558\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.3641 - accuracy: 0.8676\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3939 - accuracy: 0.8613\n"
     ]
    }
   ],
   "source": [
    "RNN(X_train_fashion, y_train_fashion, X_test_fashion, y_test_fashion, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **86.76%** and test set accuracy is **86.13%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10\n",
    "Dataset of natural images of 10 different classes\n",
    "- 50000 training images\n",
    "- 10000 test images\n",
    "- 32*32 pixels RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cifar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=990\n",
    "plt.title(\"The label of image is \"+str(y_train_cifar[x]))\n",
    "plt.imshow(X_train_cifar[x])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,707,274\n",
      "Trainable params: 1,707,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8576 - accuracy: 0.3245\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6659 - accuracy: 0.4052\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5897 - accuracy: 0.4308\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5382 - accuracy: 0.4485\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4998 - accuracy: 0.4626\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5111 - accuracy: 0.4594\n"
     ]
    }
   ],
   "source": [
    "Simple_Dense_Model(X_train_cifar, y_train_cifar, X_test_cifar, y_test_cifar, lr=0.001, input_shape=(32*32*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **46.26%** and test set accuracy is **45.94%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5243 - accuracy: 0.4427\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1258 - accuracy: 0.6049\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.9601 - accuracy: 0.6659\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8530 - accuracy: 0.7030\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7850 - accuracy: 0.7253\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9261 - accuracy: 0.6829\n"
     ]
    }
   ],
   "source": [
    "CNN(X_train_cifar, y_train_cifar, X_test_cifar, y_test_cifar, lr=0.001, input_shape=(32,32,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **72.53%** and test set accuracy is **68.29%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "Images(32x32x3) will go in row by row(\"32 rows, each row of size(32*3) at a time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, None, 256)         90368     \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 224,266\n",
      "Trainable params: 224,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 1.9783 - accuracy: 0.2608\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 98s 63ms/step - loss: 1.7924 - accuracy: 0.3313\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 1.7298 - accuracy: 0.3561\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 98s 63ms/step - loss: 1.6807 - accuracy: 0.3751\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 98s 63ms/step - loss: 1.6329 - accuracy: 0.3906\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.6137 - accuracy: 0.3955\n"
     ]
    }
   ],
   "source": [
    "RNN(X_train_cifar, y_train_cifar, X_test_cifar, y_test_cifar, lr=0.001, input_shape=(32,32*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training test accuracy is **39.06%** and test set accuracy is **39.55%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For these image type of data, the best results are by CNN and the worst results are by RNN for all the 3 datasets. Simple neuaral networks are performing near to the performance of CNN. The accuracy of  all the 3 algorithma can be increased by training for a longer duration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
